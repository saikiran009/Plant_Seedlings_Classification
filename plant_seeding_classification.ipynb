{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CATEGORIES = ['Black-grass', 'Charlock', 'Cleavers', 'Common Chickweed', 'Common wheat', 'Fat Hen', 'Loose Silky-bent',\n",
    "              'Maize', 'Scentless Mayweed', 'Shepherds Purse', 'Small-flowered Cranesbill', 'Sugar beet']\n",
    "NUM_CATEGORIES = len(CATEGORIES)\n",
    "\n",
    "\n",
    "train_dir ='train/'\n",
    "valid_dir =  'valid/'\n",
    "test_dir ='test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in CATEGORIES:\n",
    "    print('{} {} images'.format(category, len(os.listdir(os.path.join(train_dir, category)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "\n",
    "for species_num, species in enumerate(CATEGORIES):\n",
    "    for file in os.listdir(os.path.join(train_dir, species)):\n",
    "        train.append(['train/{}/{}'.format(species, file), species_num, species])\n",
    "        \n",
    "train = pd.DataFrame(train, columns=['file', 'species_num', 'species'])\n",
    "print(train.head())\n",
    "print('Training Data: ',train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Image pre-processing'''\n",
    "\n",
    "def create_mask_for_plant(image):\n",
    "    #used to convert image bgr to hsv form hue ,saturation and value , to filter out noise due to colour space\n",
    "    image_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    sensitivity = 35\n",
    "    lower_hsv = np.array([60 - sensitivity, 100, 50])\n",
    "    upper_hsv = np.array([60 + sensitivity, 255, 255])\n",
    "    #mask to remove the backgroud of the image\n",
    "    mask = cv2.inRange(image_hsv, lower_hsv, upper_hsv)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11,11))\n",
    "    #to remove edges\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def segment_plant(image):\n",
    "    mask = create_mask_for_plant(image)\n",
    "    #to crop the plant\n",
    "    output = cv2.bitwise_and(image, image, mask = mask)\n",
    "    return output\n",
    "\n",
    "def sharpen_image(image):\n",
    "    #low pass filter used\n",
    "    image_blurred = cv2.GaussianBlur(image, (0, 0), 3)\n",
    "    image_sharp = cv2.addWeighted(image, 1.5, image_blurred, -0.5, 0)\n",
    "    #print(type(image_sharp))\n",
    "    return image_sharp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "from PIL import Image\n",
    "import scipy.misc\n",
    "for i in range(len(train)):\n",
    "    img = cv2.imread(train['file'][i])\n",
    "    img = cv2.resize(img,dsize=(256,256))\n",
    "    img_stack = segment_plant(img)\n",
    "    img_stack = sharpen_image(img_stack)   \n",
    "    img_stack = np.reshape(img_stack,(256,256,3))\n",
    "    x_train.append(img_stack)\n",
    "\n",
    "x_train = np.array(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_image = cv2.imread(train['file'][len(train)-1])\n",
    "\n",
    "plt.imshow(Input_image)\n",
    "plt.title('Input image, Shape: '+str(Input_image.shape))\n",
    "plt.show()\n",
    "\n",
    "# Resized image\n",
    "plt.imshow(img)\n",
    "plt.title('Resized image, Shape: '+str(img.shape))\n",
    "plt.show()\n",
    "        \n",
    "# Processed image to Stack\n",
    "plt.imshow(np.reshape(img_stack,(256,256,3)))\n",
    "plt.title('Processed image, Shape: '+str(img_stack.shape))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#target variables one-hot encoding\n",
    "from keras.utils.np_utils import to_categorical\n",
    "labels = train['species_num']\n",
    "labels = to_categorical(labels, num_classes = len(CATEGORIES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, labels, test_size = 0.1, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_shape = x_train[0].shape\n",
    "print('Input Shape is :', input_shape)\n",
    "print(type(x_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "    shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications import ResNet50\n",
    "base_model = ResNet50(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(12, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "for layer in base_model.layers: layer.trainable = False\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.fit_generator(train_datagen.flow(x_train, y_train, batch_size=64),\n",
    "                    steps_per_epoch=len(x_train) / 32, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
